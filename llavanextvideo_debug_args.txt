--output_dir "checkpoints" --lora_enable True --lora_r 128 --lora_alpha 256 --mm_projector_lr 2e-5 --deepspeed scripts/zero2.json --model_name_or_path "lmms-lab/LLaVA-NeXT-Video-7B" --version v1 --dpo_alpha 1.0 --beta 0.1 --gamma 0 --data_path=data/data_pref_merged.jsonl --image_folder "/home/shreyasjena/BTP/datasets/COCO/pref_images" --video_folder /home/shreyasjena/BTP/datasets/WebVid/videos --mm_tunable_parts="mm_vision_tower,mm_mlp_adapter,mm_language_model" --vision_tower "openai/clip-vit-large-patch14-336" --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --mm_spatial_pool_stride 2 --mm_resampler_type "spatial_pool" --mm_spatial_pool_out_channels 1024 --group_by_modality_length True --image_aspect_ratio anyres --image_grid_pinpoints "[(336, 672), (672, 336), (672, 672), (1008, 336), (336, 1008)]" --mm_patch_merge_type spatial_unpad --bf16 True --bits 8 --num_train_epochs 1 --per_device_train_batch_size 1 --per_device_eval_batch_size 4 --gradient_accumulation_steps 8 --evaluation_strategy "no" --save_strategy "steps" --save_steps 3000 --save_total_limit 1 --learning_rate 1e-7 --weight_decay 0. --warmup_ratio 0.1 --lr_scheduler_type "linear" --logging_steps 1 --verbose_logging True --tf32 True --model_max_length 32768 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --torch_compile True --torch_compile_backend "inductor" --dataloader_drop_last True --attn_implementation "flash_attention_2" --frames_upbound 30 --run_name "llavanextvideo7b_dpo_finetune_mixed"